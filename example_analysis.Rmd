---
title: "Illustrative Example: Applying the Semiparametric Regression Method for Misclassified Competing Risks Data"
author:
- Theofanis Balanos^[Department of Biostatistics and Health Data Science, Fairbanks School of Public Health and School of Medicine, Indiana University Indianapolis, IN, USA]
- Giorgos Bakoyannis^[Department of Biostatistics and Health Data Science, Fairbanks School of Public Health and School of Medicine, Indiana University Indianapolis, IN, USA]
- Constantin T. Yiannoutsos^[Department of Epidemiology and Biostatistics, CUNY Graduate School of Public Health and Health Policy, City University of New York, NY, USA]
output:
  rmarkdown::html_document:
    theme: paper
header-includes: |
  \usepackage{enumerate,footnote,float,placeins,tabularx,graphicx,
  amsmath,amssymb,setspace,booktabs,epsfig,lastpage,url,hyperref,bbm,
  fancyhdr,mathtools,multirow,lscape}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

In this short document, we present an example illustrating how to use our proposed Semiparametric Regression Method for Misclassified Competing Risks Data.

## Step 1 – Generate External Validation Dataset

We start by generating a simulated external **validation dataset** for modeling misclassification probabilities in competing-risks data. The simulation mechanism follows the procedure described in Mpofu et al. (2020) for the double-sampling pseudo-likelihood framework, which allows for **bidirectional misclassification** between causes of failure. This external dataset will later be used to estimate the parameters of the misclassification model, which are then applied to the main analysis dataset when fitting the semiparametric regression model proposed in this work.

The data-generation procedure is contained in a separate R script, `simulate_data.R`, located on the user’s desktop.  
This script defines three main scenarios:  
1. Unidirectional misclassification  
2. Bidirectional misclassification (equal probabilities)  
3. Bidirectional misclassification (unequal probabilities)

Below, we load this simulation script, generate an **external validation dataset** under the **bidirectional (equal)** case (`cause_num = 2`) and inspect the first few rows of one example dataset.

```{r, message=FALSE, warning=FALSE}
#--- Generate a list of external validation datasets --------------------------

# Load data-generation script (follows Mpofu et al. 2020 structure)
source("simulate_data.R")

# Arguments:
# n           : number of datasets to generate
# sample.size : number of subjects per dataset
# cause_num   : misclassification scenario
#               1 = uni-directional
#               2 = bi-directional (equal probabilities)
#               3 = bi-directional (unequal probabilities)
# ds          : proportion double-sampled (internal validation)

external_data_list <- data_list(n = 1,
                                sample.size = 500,
                                cause_num = 2,
                                ds = 1.0)   # full validation, true causes observed

# Select one dataset for demonstration if more than one is generated (here 1 is generated)
dat_external <- external_data_list[[1]]

# Display first few rows of the simulated external dataset
head(dat_external)
```

### Variable Descriptions

Each simulated dataset generated by `simulate_data.R` contains the following variables:

| Variable | Description |
|-----------|-------------|
| **id** | Subject identifier. |
| **t** | True failure time \(T\). |
| **x** | Observed follow-up time (minimum of event or censoring time). |
| **c** | True cause of failure (1 = cause 1, 2 = cause 2, 0 = censored). |
| **c_obs** | Observed (possibly misclassified) cause of failure \(C^{*}\). |
| **d1** | Indicator that the *true* cause of failure is 1 \((C=1)\). |
| **d2** | Indicator that the *true* cause of failure is 2 \((C=2)\). |
| **d1_obs** | Indicator that the *observed* cause of failure is 1 \((C^{*}=1)\). |
| **d2_obs** | Indicator that the *observed* cause of failure is 2 \((C^{*}=2)\). |
| **z1** | Continuous covariate 1 (Uniform (0, 1)). |
| **z2** | Continuous covariate 2 (Normal (0, 1)). |
| **s** | Double-sampling indicator (1 = subject selected for validation sample, 0 = not selected). |
| **r** | Indicator that the *true cause* is observed (1 = true cause known, 0 = missing). |

All variables are fully simulated and serve only illustrative purposes following the data-generation structure of *Mpofu et al.* (2020).

---

## Step 2 – Estimate Misclassification Probabilities

Next, we apply the pseudo-likelihood estimation procedure of *Mpofu et al.* (2020) to the **external validation dataset** generated in Step 1. This step estimates the parameters of the logistic-regression models for the predictive values and the misclassification probabilities. The estimated coefficients (\(\hat{\gamma}\)) describe how covariates \((t, z_1, z_2)\) affect the probability of misclassifying one cause as another.  

The estimation functions are defined in the external script `pseudo_likelihood_estimation_Mpofu.R`.

```{r, message=FALSE, warning=FALSE}
#--- Load Mpofu et al. (2020) pseudo-likelihood estimation functions -----------
source("pseudo_likelihood_estimation_Mpofu.R")
```

### | Probability of Observing Cause 2 Given True Cause 1

In this case, we estimate the probability of observing cause 2 when the true cause of failure is 1; that is,

\[
P(C^{*}=2 \mid C=1,\, T,\, \mathbf{Z})
\]

representing misclassification from cause 1 → 2, and \(T = t\) denotes the event time and \(\mathbf{Z} = (z_1, z_2)\) represents the subject-specific covariates.

```{r, message=FALSE, warning=FALSE}
#--- Perform pseudo-likelihood estimation for cause 1 → 2 ---------------------
model_fit_example1 <- misclass_ps_est(dat = dat_external,
                                      true_out = "c",
                                      surr_out = "c_obs",
                                      out_interest = 1,
                                      formula_pred_val = ~ t + z1 + z2,
                                      formula_mis = ~ t + z1 + z2,
                                      ds_var = "r")

# Display estimated coefficients and standard errors
model_fit_example1$test_summary
```

### | Probability of Observing Cause 1 Given True Cause 2

Here, we estimate the probability of observing cause 1 when the true cause of failure is 2; that is,

\[
P(C^{*}=1 \mid C=2,\, T,\, \mathbf{Z}),
\]

representing misclassification from cause 2 → 1, and \(T = t\) denotes the event time and \(\mathbf{Z} = (z_1, z_2)\) represents the subject-specific covariates.

```{r, message=FALSE, warning=FALSE}
#--- Perform pseudo-likelihood estimation for cause 2 → 1 ---------------------
model_fit_example2 <- misclass_ps_est(dat = dat_external,
                                      true_out = "c",
                                      surr_out = "c_obs",
                                      out_interest = 2,
                                      formula_pred_val = ~ t + z1 + z2,
                                      formula_mis = ~ t + z1 + z2,
                                      ds_var = "r")

# Display estimated coefficients and standard errors
model_fit_example2$test_summary
```

---

## Step 3 – Generate Main Analysis Dataset

In this step, we generate a **main dataset** representing the study cohort in which the true causes of failure are *not observed*. Only the misclassified causes (\(C^{*}\)) are available for analysis. This dataset will later be analyzed using the proposed semiparametric regression method, incorporating the externally estimated misclassification probabilities obtained in Step 2.  

The same simulation procedure used for the external validation data is employed here (see `simulate_data.R`), but we set the **double-sampling proportion** (`ds = 0`) so that no subjects have their true causes observed.

```{r, message=FALSE, warning=FALSE}
#--- Generate the main (analysis) dataset -------------------------------------

# Load the same simulation script (already loaded earlier, shown again for clarity)
source("simulate_data.R")

# Create one main dataset with no internal validation (ds = 0)
main_data_list <- data_list(n = 1,
                            sample.size = 1000,
                            cause_num = 2,   # bidirectional equal misclassification
                            ds = 0.0)        # no double-sampling (true causes unobserved)

dat_main <- main_data_list[[1]]

# Display first few rows of the main dataset
head(dat_main)
```

#### Note

Variable definitions are the same as in Step 1.

---

## Step 4 – Compute Misclassification Probabilities for the Main Dataset

We now compute the estimated misclassification probabilities for each subject in the **main analysis dataset** using the pseudo-likelihood models fitted on the external validation dataset (Step 2).  
Specifically,

- \( p_{21} = P(C^{*}=2 \mid C=1, T,\, \mathbf{Z}) \): probability that true cause 1 is observed as 2  
- \( p_{12} = P(C^{*}=1 \mid C=2, T,\, \mathbf{Z}) \): probability that true cause 2 is observed as 1

```{r, message=FALSE, warning=FALSE}
#--- Step 4: Compute predicted misclassification probabilities -----------------

# Extract Mpofu model objects from Step 2
mod_21 <- model_fit_example1$model_miscl   # C=1 → observed as 2
mod_12 <- model_fit_example2$model_miscl   # C=2 → observed as 1

# Predict misclassification probabilities in the main dataset
dat_main$p21 <- predict(mod_21, newdata = dat_main, type = "response")
dat_main$p12 <- predict(mod_12, newdata = dat_main, type = "response")

# Display first few rows with misclassification probabilities
head(dat_main[, c("t", "z1", "z2", "p12", "p21")])
```

---

## Step 5 – Apply the Proposed Semiparametric Regression Method

In this step, we apply the proposed semiparametric regression estimator to the **main analysis dataset**. This method uses the externally estimated misclassification probabilities \( p_{12} \) and \( p_{21} \) obtained in Step 4 to correct the cause-specific hazard estimation.  

The estimation function `bssmle()` is defined in the external R script `bssmle.R`.

```{r, message=FALSE, warning=FALSE}
#--- Load the proposed semiparametric regression function ---------------------
source("bssmle.R")

#--- Fit the model to the main dataset ----------------------------------------
# Specify which covariates to include (must match column names in dat_main)
fit_bssmle <- bssmle(dat_main, covariates = c("z1", "z2"))

#--- Interpretation helper ----------------------------------------------------
# The returned object 'fit_bssmle' is a numeric vector that concatenates:
#   (1) phi1: B-spline coefficients for baseline hazard of cause 1
#   (2) phi2: B-spline coefficients for baseline hazard of cause 2
#   (3) beta1: regression coefficients for cause 1
#   (4) beta2: regression coefficients for cause 2
#
# For q covariates and n spline basis functions, the total length is 2*n + 2*q.

covariates <- c("z1", "z2")   # keep consistent with the function call above

beta_vec <- fit_bssmle
q <- length(covariates)

# Recover number of spline basis coefficients per cause
n <- (length(beta_vec) - 2*q) / 2
stopifnot(n == floor(n), n > 0)

#--- Extract parameter blocks -------------------------------------------------
phi1  <- beta_vec[1:n]                      # baseline hazard coefficients, cause 1
phi2  <- beta_vec[(n+1):(2*n)]              # baseline hazard coefficients, cause 2
beta1 <- beta_vec[(2*n+1):(2*n+q)]          # regression coefs, cause 1
beta2 <- beta_vec[(2*n+q+1):(2*n+2*q)]      # regression coefs, cause 2

#--- Label and present the regression coefficients ---------------------------
names(beta1) <- paste0("Cause1:", covariates)
names(beta2) <- paste0("Cause2:", covariates)

coef_table <- data.frame(
  cause     = rep(c("Cause 1","Cause 2"), each = q),
  covariate = rep(covariates, times = 2),
  estimate  = c(beta1, beta2)
)

cat("\nEstimated regression coefficients for each cause:\n")
print(coef_table, row.names = FALSE)

cat("\nNumber of B-spline basis coefficients per cause:", n, "\n")
```

#### Notes

* The vector `fit_bssmle` concatenates all estimated parameters in the order
  \((\phi_1, \phi_2, \beta_1, \beta_2)\).

  * \(\phi_1, \phi_2\): spline coefficients describing the two baseline hazards.
  * \(\beta_1, \beta_2\): regression coefficients for the covariates under each cause.
* With two covariates \((z_1, z_2)\), the **last four elements** of `fit_bssmle` correspond to
  \((\beta_{1,z1}, \beta_{1,z2}, \beta_{2,z1}, \beta_{2,z2})\).
* These estimates incorporate the externally derived misclassification probabilities,
  providing bias-corrected cause-specific hazard estimates under time- and covariate-dependent misclassification.

---

## Step 6 – Sensitivity Analysis for Misclassification Probabilities  

To examine the robustness of our method when the true misclassification rates differ from those estimated in the validation data, we conduct a sensitivity analysis following the framework described in the relevant Section of the paper.  

Under this framework, the *adjusted misclassification probabilities* are given by  
\[
\pi^*_{jh}(X,\mathbf{Z},T;\gamma_{0,h},\eta)
   = g(\gamma'_{0,h}\,\tilde{\mathbf{W}} + \eta S),
\]
where \(g(\cdot)\) is the logistic function, \(\tilde{\mathbf{W}}\) represents the covariates associated with misclassification (e.g., event time \(T\) and covariates \(\mathbf{Z}\)) and \(S\) is an indicator for the data source (\(S=0\) for the external validation dataset and \(S=1\) for the main analysis dataset). The parameter \(\eta\) controls how much the misclassification mechanism in the main study deviates from that estimated in the external validation sample. In this setting, \(\eta = 0\) corresponds to **perfect transportability**, i.e. same misclassification probabilities, while \(\eta \neq 0\) represents a violation of transportability, i.e. there are diﬀerences between main and external datasets.

For practical implementation, we adjust both estimated misclassification probabilities  
\[
p_{21} = P(C^{*}=2 \mid C=1,\,T=t,\,\mathbf{Z}), \qquad
p_{12} = P(C^{*}=1 \mid C=2,\,T=t,\,\mathbf{Z}),
\]
by applying a **logit shift** with \(\eta \in \{-0.5,-0.25,0,0.25,0.5\}\):  
\[
\text{logit}\{p_{jh}^{(\eta)}\}
   = \text{logit}\{p_{jh}\} + \eta,
   \quad\text{so}\quad
   p_{jh}^{(\eta)} = \operatorname{logit}^{-1}\{\operatorname{logit}(p_{jh})+\eta\}.
\]

This transformation is a direct empirical version of \(\pi^*_{jh}(X,\mathbf{Z},T;\gamma_{0,h},\eta) = g(\gamma'_{0,h}\tilde{\mathbf{W}}+\eta S)\) for the main analysis dataset (\(S=1\)).  

For each \(\eta\), we re-fit the proposed semiparametric regression model using `bssmle()` and record the resulting regression coefficients for both causes.  

```{r, message=FALSE, warning=FALSE}
#--- Sensitivity analysis implementation (bidirectional adjustment) -----------

etas <- c(-0.5, -0.25, 0, 0.25, 0.5)
covariates <- c("z1", "z2")

fit_at_eta <- function(eta, dat, covariates) {
  dat_eta <- dat

  if (abs(eta) > 1e-12) {
    eps <- 1e-12

    # Adjust p21 (C=1 → observed as 2)
    p <- pmin(pmax(dat_eta$p21, eps), 1 - eps)
    dat_eta$p21 <- plogis(qlogis(p) + eta)

    # Adjust p12 (C=2 → observed as 1)
    p <- pmin(pmax(dat_eta$p12, eps), 1 - eps)
    dat_eta$p12 <- plogis(qlogis(p) + eta)
  }
  # else leave dat_eta$p12 and dat_eta$p21 unchanged

  beta_vec <- bssmle(dat_eta, covariates)

  q <- length(covariates)
  n <- (length(beta_vec) - 2*q) / 2
  if (!is.finite(n) || n != floor(n) || n <= 0) return(NULL)

  beta1 <- beta_vec[(2*n + 1):(2*n + q)]
  beta2 <- beta_vec[(2*n + q + 1):(2*n + 2*q)]
  names(beta1) <- paste0("Cause1:", covariates)
  names(beta2) <- paste0("Cause2:", covariates)

  coef_table <- data.frame(
    eta       = eta,
    cause     = rep(c("Cause 1", "Cause 2"), each = q),
    covariate = rep(covariates, times = 2),
    estimate  = c(beta1, beta2)
  )

  cat("\nEstimated regression coefficients for each cause (eta =", eta, "):\n")
  print(coef_table, row.names = FALSE)
  return(coef_table)
}

# Run sensitivity analysis across η values
sens_list <- lapply(etas, fit_at_eta, dat = dat_main, covariates = covariates)
```
#### Note

Please note here that results for \(\eta = 0\) correspond to those from Step 5, since \(\eta = 0\) represents the baseline case without any sensitivity adjustment.

---

## Step 7 – Bootstrap Standard Errors

To assess the sampling variability of the proposed estimator, we can use a simple non-parametric **bootstrap**. Here, we resample individuals (with replacement) from the **main dataset** and re-fit the model on each bootstrap replicate. For demonstration, we use **10 bootstrap samples**, but users can increase this number (e.g., 100 or 1000) depending on computational resources and needs.

Each bootstrap fit returns a full parameter vector; the standard deviation of these estimates provides approximate standard errors. Note that the bootstrap is performed only for the baseline case with \(\eta = 0\) (the model estimated in Step 5), and not for the sensitivity analyses in Step 6. 

```{r, message=FALSE, warning=FALSE}
set.seed(2026)  # for reproducibility
n_boot <- 10    # number of bootstrap replicates (adjust as needed)

boot_results <- replicate(n_boot, {
  # Resample individuals with replacement
  idx <- sample(seq_len(nrow(dat_main)), replace = TRUE)
  dat_boot <- dat_main[idx, ]
  
  # Fit the model on each bootstrap sample
  bssmle(dat_boot, covariates = c("z1", "z2"))
}, simplify = "array")

# Compute bootstrap-based standard deviations (SEs)
boot_sds <- apply(boot_results, 1, sd, na.rm = TRUE)

### Summarize bootstrap inference results -------------------------------------

# Direct model fit (from Step 5)
theta_hat <- bssmle(dat_main, covariates = c("z1","z2"))

# Extract regression coefficients (last 4)
q <- 2
n <- (length(theta_hat) - 2*q) / 2
beta1_hat <- theta_hat[(2*n+1):(2*n+q)]
beta2_hat <- theta_hat[(2*n+q+1):(2*n+2*q)]

# Extract corresponding bootstrap SEs
beta1_se <- boot_sds[(2*n+1):(2*n+q)]
beta2_se <- boot_sds[(2*n+q+1):(2*n+2*q)]

# Wald statistics centered at direct fit
boot_table <- data.frame(
  cause     = rep(c("Cause 1","Cause 2"), each = q),
  covariate = rep(c("z1","z2"), times = 2),
  estimate  = c(beta1_hat, beta2_hat),  # direct fit (point estimate)
  SE        = c(beta1_se, beta2_se)
)

boot_table$z_value <- boot_table$estimate / boot_table$SE
boot_table$p_value <- 2 * (1 - pnorm(abs(boot_table$z_value)))
boot_table$Lower95 <- boot_table$estimate - 1.96 * boot_table$SE
boot_table$Upper95 <- boot_table$estimate + 1.96 * boot_table$SE

# Nicely formatted output table
knitr::kable(
  boot_table,
  digits = c(NA, NA, 3, 3, 3, 3, 3, 3),
  caption = "Bootstrap-based Wald inference for regression coefficients (10 replicates)."
)
```

### Notes

* The number of bootstrap replicates (`n_boot`) can be increased to improve accuracy.
* Each bootstrap fit may take a few seconds to minutes depending on dataset size and computing power.

**Tip for readers:**
Use `n_boot = 100` for a quick precision check, or `n_boot = 1000` for publication-grade inference.

---

## Step 8 – Plotting Cumulative Incidence Functions Across η Values  

In this final step, we illustrate how the estimated cumulative incidence functions (CIFs) change under different sensitivity settings for the parameter \(\eta\). Recall that \(\eta\) controls the degree of deviation between the misclassification mechanism in the main study and the one estimated from the validation data. By refitting the semiparametric model for five values of \(\eta \in \{-0.5, -0.25, 0, 0.25, 0.5\}\), we can visualize how the predicted event probabilities evolve when assuming weaker or stronger transportability of the misclassification model.  

To make the comparison meaningful, we evaluate the CIFs for a **representative subject**, defined as one whose continuous covariates \(z_1\) and \(z_2\) are set to their sample means. For each \(\eta\), the function `bssmle()` is re-fitted using the adjusted misclassification probabilities and the resulting spline coefficients and regression parameters are used to reconstruct the **baseline hazards**, **cause-specific hazards** and the **CIFs** over a fine time grid. The CIFs in this step are computed using the fitted cumulative hazards and regression parameters obtained from our semiparametric proportional cause-specific hazards model. Specifically, for each cause \( j = 1, 2 \), the baseline cumulative hazard is estimated as  
\[
\hat{\Lambda}_{0j}(t) = \exp\{ \mathbf{B}(t)^{\top} \hat{\boldsymbol{\phi}}_j \},
\]
where \(\mathbf{B}(t)\) denotes the B-spline basis functions and \(\hat{\boldsymbol{\phi}}_j\) are the corresponding spline coefficients.  

The subject-specific cumulative hazards are then given by  
\[
\hat{\Lambda}_j(t \mid \mathbf{Z}) = \hat{\Lambda}_{0j}(t) \exp(\mathbf{Z}^{\top}\hat{\boldsymbol{\beta}}_j),
\]
and the overall survival function is  
\[
\hat{S}(t \mid \mathbf{Z}) = \exp\!\left[-\sum_{j=1}^{2}\hat{\Lambda}_j(t \mid \mathbf{Z})\right].
\]

Finally, the cumulative incidence function for cause \( j \) is obtained by numerical integration of the cause-specific hazard over time:  
\[
\hat{F}_j(t \mid \mathbf{Z}) = \int_0^t \hat{S}(u \mid \mathbf{Z})\, d\hat{\Lambda}_j(u \mid \mathbf{Z}),
\]
which is approximated using cumulative sums over a fine time grid. These formulas correspond directly to the proportional cause-specific hazards formulation and the cumulative incidence representation of the paper.

The resulting plots display two panels, one for each cause of failure. The x-axis represents time and the y-axis shows the estimated probability of experiencing each event by time \(t\) (ranging from 0 to 1). Each curve corresponds to a specific \(\eta\) value, allowing a visual assessment of how sensitive the estimated CIFs are to plausible deviations from the baseline misclassification assumptions.  

```{r, message=FALSE, warning=FALSE}
#-----------------------------------------------#
# Plot CIFs for the Five η Scenarios
#-----------------------------------------------#

library(splines)

# Sensitivity parameters to test
etas <- c(-0.5, -0.25, 0, 0.25, 0.5)
covariates <- c("z1", "z2")

# Define a representative subject profile:
#   z1 = mean of the continuous covariate,
#   z2 = mean of the continuous covariate
Z1 <- c(mean(dat_main$z1, na.rm = TRUE), mean(dat_main$z2, na.rm = TRUE))
Z2 <- Z1

# --- Fit the semiparametric model for each η value ---
# Each fit adjusts the misclassification probabilities by a logit shift of size η
fit_eta <- lapply(etas, function(eta) {
  dat_eta <- dat_main
  eps <- 1e-12
  dat_eta$p21 <- plogis(qlogis(pmin(pmax(dat_eta$p21, eps), 1 - eps)) + eta)
  dat_eta$p12 <- plogis(qlogis(pmin(pmax(dat_eta$p12, eps), 1 - eps)) + eta)
  bssmle(dat_eta, covariates = covariates)
})
names(fit_eta) <- paste0("eta_", etas)

# --- Build spline basis for the time grid ---
# This recreates the same spline setup used during model estimation (see function `bssmle()`)
t_fit <- dat_main$x
nk <- floor(length(t_fit)^(1/3))                              # number of interior knots
knots_fit <- quantile(t_fit, seq(0, 1, by = 1/(nk + 1)))[2:(nk + 1)]
bkn_fit   <- range(t_fit, na.rm = TRUE)
deg_fit   <- 3                                                # cubic B-splines
t_grid <- seq(bkn_fit[1], bkn_fit[2], length.out = 200)       # fine time grid
Bpred  <- bs(t_grid, knots = knots_fit, degree = deg_fit,
             intercept = TRUE, Boundary.knots = bkn_fit)
dt <- c(0, diff(t_grid))                                      # time step differences

# --- Function to compute CIFs from model coefficients ---
# Uses baseline hazard splines and covariate effects to get F1(t) and F2(t)
compute_cif <- function(res, Bpred, Z1, Z2, t_grid, dt) {
  n  <- (length(res) - 4) / 2
  phi1 <- res[1:n]; phi2 <- res[(n+1):(2*n)]
  b1   <- res[(2*n+1):(2*n+2)]; b2 <- res[(2*n+3):(2*n+4)]

  # Baseline cumulative hazards
  H01 <- exp(Bpred %*% phi1)
  H02 <- exp(Bpred %*% phi2)

  # Subject-specific cumulative hazards
  lp1 <- sum(Z1 * b1); lp2 <- sum(Z2 * b2)
  H1 <- H01 * exp(lp1)
  H2 <- H02 * exp(lp2)

  # Instantaneous hazards and CIFs
  h1 <- c(0, diff(H1)) / dt
  h2 <- c(0, diff(H2)) / dt
  h1[!is.finite(h1)] <- 0; h2[!is.finite(h2)] <- 0

  S_t <- exp(-(H1 + H2))             # survival function
  F1  <- cumsum(S_t * h1 * dt)       # CIF for cause 1
  F2  <- cumsum(S_t * h2 * dt)       # CIF for cause 2
  list(F1 = F1, F2 = F2)
}

# --- Compute CIFs for all η values ---
cif_list <- lapply(fit_eta, compute_cif, Bpred = Bpred,
                   Z1 = Z1, Z2 = Z2, t_grid = t_grid, dt = dt)

# --- Plot the CIFs for each cause ---
# y-axis fixed between 0 and 1 for comparability
par(mfrow = c(1, 2), mar = c(4.5, 4.5, 3, 1))
cols <- gray.colors(length(etas), start = 0.1, end = 0.7)

## (a) Cause 1
plot(t_grid, cif_list[[1]]$F1, type = "l", lwd = 2, ylim = c(0, 1),
     xlab = "Time", ylab = "Cumulative incidence function",
     main = "(a) Cause 1")
for (i in seq_along(etas)) {
  lines(t_grid, cif_list[[i]]$F1, col = cols[i], lwd = 2, lty = i)
}
legend("topleft", legend = sapply(etas, \(e) bquote(eta == .(e))),
       col = cols, lwd = 2, lty = seq_along(etas),
       bty = "n", cex = 0.8)

## (b) Cause 2
plot(t_grid, cif_list[[1]]$F2, type = "l", lwd = 2, ylim = c(0, 1),
     xlab = "Time", ylab = "Cumulative incidence function",
     main = "(b) Cause 2")
for (i in seq_along(etas)) {
  lines(t_grid, cif_list[[i]]$F2, col = cols[i], lwd = 2, lty = i)
}
legend("topleft", legend = sapply(etas, \(e) bquote(eta == .(e))),
       col = cols, lwd = 2, lty = seq_along(etas),
       bty = "n", cex = 0.8)
```

---

## Concluding Remarks

This example illustrated how to apply our semiparametric regression method for competing risks data with misclassified causes of failure. Using simulated data, we demonstrated how to estimate misclassification probabilities from an external validation sample, fit the proposed model using these probabilities and assess robustness through sensitivity analysis and bootstrap inference. The approach yields corrected and interpretable estimates of cause-specific effects and cumulative incidence functions, providing a practical framework for analyzing competing risks data subject to outcome misclassification.





